{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install transformers datasets peft evaluate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fc6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2416f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec44373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf6d46",
   "metadata": {},
   "source": [
    "#### using an uncased model as they always perform better in most cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7388150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'allenai/scibert_scivocab_uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935cb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  \n",
    "#num_labels = 2 meaning we wake it a yes or no kinda scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac076ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223561f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"deepmind/math_dataset\", \"calculus__differentiate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,   #let us use 16 rank\n",
    "    lora_alpha=32,   #scaling factor\n",
    "    target_modules=[\"query\", \"value\"],          #specific layers to apply lora to\n",
    "    lora_dropout=0.05,     \n",
    "    bias=\"none\",     #bias type for LoRA\n",
    "    task_type=\"SEQ_CLS\"   #sequence classification task, simply denoting correct or incorrect for a question\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84749b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)   #specifically applying LoRA to our SCIBERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extracting questions from the input examples and then using tokenizer to process them\n",
    "    \n",
    "    Arg: examples(dict) = dictionary containing batvch of examples\n",
    "    \n",
    "    Returns: labels(dict) = dictionary containing tokenized values to explain inputs_id and attention mask\n",
    "    \n",
    "    \"\"\"\n",
    "    questions = examples[\"question\"]\n",
    "    inputs = tokenizer(questions, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    inputs[\"labels\"] = [1 if answer == \"correct\" else 0 for answer in examples[\"answer\"]]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_function??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0], dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f124f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator =  DataCollatorWithPadding(tokenizer=tokenizer, padding=True)   #ensuring consistent, dynamic batch padding when training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f884f",
   "metadata": {},
   "source": [
    "### Defining training arguments now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f170cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return {'f1': f1, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f04663",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"calculus_lora_scibert\",    #specifying where to save our model\n",
    "    num_train_epochs=1,    #number of training epochs done\n",
    "    per_device_train_batch_size=16,     #gpu processes 16 samples during training\n",
    "    per_device_eval_batch_size=16,       #process 16 samples during evaluation\n",
    "    gradient_accumulation_steps=2,     #number of forward passes before backpropagation by the per_device_train_batch_size\n",
    "    learning_rate=1e-4,       #step size taken during learning\n",
    "    fp16=True,        # memory efficiency, helps speed entire process\n",
    "    logging_steps=50,   #how often metrics are logged\n",
    "    save_steps=100,  #model chcekpoint set to 100\n",
    "    evaluation_strategy=\"epoch\"    #explains how often we evaluate our model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c726626",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=preprocessed_datasets[\"train\"],\n",
    "    eval_dataset=preprocessed_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad078f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17754aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our fine-tuned model\n",
    "save_directory = \"calculus_lora_scibert_saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d543a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model saved to: {save_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i have to type here every hour so it doesnt time out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
